{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text Classification.ipynb","provenance":[],"mount_file_id":"17HwAwI2GzA9yz-L2KWeDmbMU8En1YrxN","authorship_tag":"ABX9TyOQas0Vsu+bKJXNsdAvfHmd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"nk4GzpV_ruJ7","executionInfo":{"status":"ok","timestamp":1627552414671,"user_tz":-330,"elapsed":377,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["import torch"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"YoGaxd6MJH5z","executionInfo":{"status":"ok","timestamp":1627552286706,"user_tz":-330,"elapsed":5,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["import os"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"LsH8n4hdPBr_","executionInfo":{"status":"ok","timestamp":1627552286707,"user_tz":-330,"elapsed":4,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["os.chdir('/content/drive/MyDrive/Text Classification')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"7C94OwzPPJuj","executionInfo":{"status":"ok","timestamp":1627552287350,"user_tz":-330,"elapsed":647,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["from sklearn.model_selection import train_test_split"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCXvLf70PY33","executionInfo":{"status":"ok","timestamp":1627552289611,"user_tz":-330,"elapsed":2262,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["import pandas as pd\n","df=pd.read_csv('IMDB Dataset.csv')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"818yFSNWQCEz","executionInfo":{"status":"ok","timestamp":1627552289612,"user_tz":-330,"elapsed":7,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["X,y = df['review'].values,df['sentiment'].values\n","x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vXf6t0TyQC_g"},"source":["# Data analysis"]},{"cell_type":"code","metadata":{"id":"z2Pz9CiJQGZT","executionInfo":{"status":"ok","timestamp":1627552293185,"user_tz":-330,"elapsed":3,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["from collections import Counter\n","import re"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRwADB2gYzFt","executionInfo":{"status":"ok","timestamp":1627552293579,"user_tz":-330,"elapsed":5,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["import numpy as np"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJaBecDXRF1j","executionInfo":{"status":"ok","timestamp":1627552294867,"user_tz":-330,"elapsed":1292,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["import nltk"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9Wt_DMIRLji","executionInfo":{"status":"ok","timestamp":1627552294868,"user_tz":-330,"elapsed":20,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["from nltk.corpus import stopwords "],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CAd2o7rDRjvq","executionInfo":{"status":"ok","timestamp":1627552294869,"user_tz":-330,"elapsed":19,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}},"outputId":"f99c1f47-1ad0-4696-a161-b2de35a38c08"},"source":["nltk.download('stopwords')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"XLObV2ZgRfUE","executionInfo":{"status":"ok","timestamp":1627552294870,"user_tz":-330,"elapsed":16,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["stop_words = set(stopwords.words('english'))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"vULW9NEsQjVK","executionInfo":{"status":"ok","timestamp":1627552294870,"user_tz":-330,"elapsed":16,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["def preprocess_sen(s):\n","\n","  # Remove all non-word characters (everything except numbers and letters)\n","  s = re.sub(r\"[^\\w\\s]\", '', s)\n","  # Replace all runs of whitespaces with no space\n","  s = re.sub(r\"\\s+\",\" \", s)\n","  # replace digits with no space\n","  s = re.sub(r\"\\d\", '', s)\n","\n","  return s\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUyCz00eV1wT","executionInfo":{"status":"ok","timestamp":1627552350876,"user_tz":-330,"elapsed":404,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["def tockenize(x_train,y_train,x_val,y_val):\n","    word_list = []\n","    \n","    for sen in x_train:\n","      sen=sen.lower()\n","      sen=preprocess_sen(sen)\n","      \n","      for word in sen.split():\n","        if word not in stop_words:\n","          word_list.append(word)\n","\n","    word_freq=Counter(word_list)\n","    imp_words = sorted(word_freq,key=word_freq.get,reverse=True)[:3000]\n","    \n","    onehot_dict = {w:i+1 for i,w in enumerate(imp_words)}\n","    \n","    # tockenize\n","    final_list_train,final_list_test = [],[]\n","    for sent in x_train:\n","      sent=sent.lower()\n","      sent=preprocess_sen(sent)\n","      final_list_train.append([onehot_dict[word] for word in sent.split() \n","                                     if word in onehot_dict.keys()])\n","    for sent in x_val:\n","      sent=sent.lower()\n","      sent=preprocess_sen(sent)\n","      final_list_test.append([onehot_dict[word] for word in sent.split() if word in onehot_dict.keys()])\n","  \n","    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n","    encoded_test = [1 if label =='positive' else 0 for label in y_val] \n","    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZd6CLDuWgmT","executionInfo":{"status":"ok","timestamp":1627552370710,"user_tz":-330,"elapsed":14499,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}},"outputId":"fa59abda-02d0-4e93-d272-0e30fe03172b"},"source":["X_train,y_train,X_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gIEW0PDyWw4M","executionInfo":{"status":"ok","timestamp":1627552375912,"user_tz":-330,"elapsed":390,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}},"outputId":"5914234c-22e6-4f94-fa90-b08ed1568839"},"source":["print(f'Length of vocabulary is {len(vocab)}')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Length of vocabulary is 3000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"3GguhxuBoYmK","executionInfo":{"status":"ok","timestamp":1627552378564,"user_tz":-330,"elapsed":689,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}},"outputId":"bfc2ea3a-0b7a-4001-ea81-3001e3016357"},"source":["import matplotlib.pyplot as plt\n","rev_len = [len(i) for i in x_train]\n","pd.Series(rev_len).hist()\n","plt.show()\n","pd.Series(rev_len).describe()"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"execute_result","data":{"text/plain":["count    37500.000000\n","mean      1307.100160\n","std        978.422371\n","min         32.000000\n","25%        699.000000\n","50%        970.000000\n","75%       1591.000000\n","max      10363.000000\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"idB1YDpzoe1Q","executionInfo":{"status":"ok","timestamp":1627552381615,"user_tz":-330,"elapsed":385,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["def padding_(sentences, seq_len):\n","    features = np.zeros((len(sentences), seq_len),dtype=int)\n","    for ii, review in enumerate(sentences):\n","        if len(review) != 0:\n","            features[ii, -len(review):] = np.array(review)[:seq_len]\n","    return features"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"inM75GKXpSSD","executionInfo":{"status":"ok","timestamp":1627552390716,"user_tz":-330,"elapsed":1076,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["X_train_pad = padding_(X_train,1000)\n","X_test_pad = padding_(X_test,1000)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fkxp3_B8pejx","executionInfo":{"status":"ok","timestamp":1627552418498,"user_tz":-330,"elapsed":415,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["from torch.utils.data import TensorDataset, DataLoader\n","# create Tensor datasets\n","train_data = TensorDataset(torch.from_numpy(X_train_pad), torch.from_numpy(y_train))\n","valid_data = TensorDataset(torch.from_numpy(X_test_pad), torch.from_numpy(y_test))\n","\n","# dataloaders\n","batch_size = 50\n","\n","# make sure to SHUFFLE your data\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gwLxE8-3pmrW","executionInfo":{"status":"ok","timestamp":1627552421501,"user_tz":-330,"elapsed":8,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}},"outputId":"4bda9d98-495a-4b60-be23-aff483820b77"},"source":["# obtain one batch of training data\n","dataiter = iter(train_loader)\n","sample_x, sample_y = dataiter.next()\n","\n","print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n","print('Sample input: \\n', sample_x)\n","print('Sample input: \\n', sample_y)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Sample input size:  torch.Size([50, 1000])\n","Sample input: \n"," tensor([[   0,    0,    0,  ...,    3, 1940,  687],\n","        [   0,    0,    0,  ...,    2,   70, 1300],\n","        [   0,    0,    0,  ...,   87,  973,    3],\n","        ...,\n","        [   0,    0,    0,  ...,   43,   57,    2],\n","        [   0,    0,    0,  ...,  371,   16,  566],\n","        [   0,    0,    0,  ...,  259, 1188,  354]])\n","Sample input: \n"," tensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n","        1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n","        1, 0])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KP-P4wUHrPs8"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"mdHT9Ymqqk46","executionInfo":{"status":"ok","timestamp":1627552424487,"user_tz":-330,"elapsed":7,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SentimentRNN(nn.Module):\n","    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n","        super(SentimentRNN,self).__init__()\n"," \n","        self.output_dim = output_dim\n","        self.hidden_dim = hidden_dim\n"," \n","        self.no_layers = no_layers\n","        self.vocab_size = vocab_size\n","    \n","        # embedding and LSTM layers\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        #lstm\n","        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n","                           num_layers=no_layers, batch_first=True)\n","        \n","        \n","        # dropout layer\n","        self.dropout = nn.Dropout(0.3)\n","    \n","        # linear and sigmoid layer\n","        self.fc = nn.Linear(self.hidden_dim, output_dim)\n","        self.sig = nn.Sigmoid()\n","        \n","    def forward(self,x,hidden):\n","        batch_size = x.size(0)\n","        # embeddings and lstm_out\n","        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n","        #print(embeds.shape)  #[50, 500, 1000]\n","        lstm_out, hidden = self.lstm(embeds, hidden)\n","        \n","        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n","        \n","        # dropout and fully connected layer\n","        out = self.dropout(lstm_out)\n","        out = self.fc(out)\n","        \n","        # sigmoid function\n","        sig_out = self.sig(out)\n","        \n","        # reshape to be batch_size first\n","        sig_out = sig_out.view(batch_size, -1)\n","\n","        sig_out = sig_out[:, -1] # get last batch of labels\n","        \n","        # return last sigmoid output and hidden state\n","        return sig_out, hidden\n","        \n","        \n","        \n","    def init_hidden(self, batch_size):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n","        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n","        hidden = (h0,c0)\n","        return hidden\n","\n","              "],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"314hR9yhq2n6","executionInfo":{"status":"ok","timestamp":1627552428132,"user_tz":-330,"elapsed":383,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}},"outputId":"087571ec-bd55-4d88-b0fe-7dd506e2e74a"},"source":["is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, CPU used\")"],"execution_count":26,"outputs":[{"output_type":"stream","text":["GPU is available\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ra0P8734qrPR","executionInfo":{"status":"ok","timestamp":1627552436450,"user_tz":-330,"elapsed":6577,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}},"outputId":"a6394d4d-444a-4c03-a797-6e09a41e94a7"},"source":["no_layers = 2\n","vocab_size = len(vocab) + 1 #extra 1 for padding\n","embedding_dim = 64\n","output_dim = 1\n","hidden_dim = 256\n","\n","\n","model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n","\n","#moving to gpu\n","model.to(device)\n","\n","print(model)\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["SentimentRNN(\n","  (embedding): Embedding(3001, 64)\n","  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (fc): Linear(in_features=256, out_features=1, bias=True)\n","  (sig): Sigmoid()\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ywU8C6Iwq8cb","executionInfo":{"status":"ok","timestamp":1627552439540,"user_tz":-330,"elapsed":382,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["# loss and optimization functions\n","lr=0.001\n","\n","criterion = nn.BCELoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","# function to predict accuracy\n","def acc(pred,label):\n","    pred = torch.round(pred.squeeze())\n","    return torch.sum(pred == label.squeeze()).item()"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BZAwF7jOq_3i","executionInfo":{"status":"ok","timestamp":1627553353448,"user_tz":-330,"elapsed":619848,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}},"outputId":"4dfdd864-5943-43c4-e4e5-c431d7ec7e01"},"source":["clip = 5\n","epochs = 5 \n","valid_loss_min = np.Inf\n","# train for some number of epochs\n","epoch_tr_loss,epoch_vl_loss = [],[]\n","epoch_tr_acc,epoch_vl_acc = [],[]\n","\n","for epoch in range(epochs):\n","    train_losses = []\n","    train_acc = 0.0\n","    model.train()\n","    # initialize hidden state \n","    h = model.init_hidden(batch_size)\n","    for inputs, labels in train_loader:\n","        \n","        inputs, labels = inputs.to(device), labels.to(device)   \n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","        h = tuple([each.data for each in h])\n","        \n","        model.zero_grad()\n","        output,h = model(inputs,h)\n","        \n","        # calculate the loss and perform backprop\n","        loss = criterion(output.squeeze(), labels.float())\n","        loss.backward()\n","        train_losses.append(loss.item())\n","        # calculating accuracy\n","        accuracy = acc(output,labels)\n","        train_acc += accuracy\n","        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n"," \n","    \n","        \n","    val_h = model.init_hidden(batch_size)\n","    val_losses = []\n","    val_acc = 0.0\n","    model.eval()\n","    for inputs, labels in valid_loader:\n","            val_h = tuple([each.data for each in val_h])\n","\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            output, val_h = model(inputs, val_h)\n","            val_loss = criterion(output.squeeze(), labels.float())\n","\n","            val_losses.append(val_loss.item())\n","            \n","            accuracy = acc(output,labels)\n","            val_acc += accuracy\n","            \n","    epoch_train_loss = np.mean(train_losses)\n","    epoch_val_loss = np.mean(val_losses)\n","    epoch_train_acc = train_acc/len(train_loader.dataset)\n","    epoch_val_acc = val_acc/len(valid_loader.dataset)\n","    epoch_tr_loss.append(epoch_train_loss)\n","    epoch_vl_loss.append(epoch_val_loss)\n","    epoch_tr_acc.append(epoch_train_acc)\n","    epoch_vl_acc.append(epoch_val_acc)\n","    print(f'Epoch {epoch+1}') \n","    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n","    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n","    if epoch_val_loss <= valid_loss_min:\n","        torch.save(model.state_dict(), 'state_dict.pt')\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n","        valid_loss_min = epoch_val_loss\n","    print(25*'==')"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Epoch 1\n","train_loss : 0.2947704809308052 val_loss : 0.2959631260037422\n","train_accuracy : 87.58666666666667 val_accuracy : 87.58399999999999\n","Validation loss decreased (inf --> 0.295963).  Saving model ...\n","==================================================\n","Epoch 2\n","train_loss : 0.25420869003733 val_loss : 0.29820521467924116\n","train_accuracy : 89.656 val_accuracy : 87.67200000000001\n","==================================================\n","Epoch 3\n","train_loss : 0.21790188250442347 val_loss : 0.3201303503662348\n","train_accuracy : 91.30933333333333 val_accuracy : 87.536\n","==================================================\n","Epoch 4\n","train_loss : 0.17319306964427233 val_loss : 0.31275515326857567\n","train_accuracy : 93.304 val_accuracy : 87.78399999999999\n","==================================================\n","Epoch 5\n","train_loss : 0.11554183307910959 val_loss : 0.3835387982279062\n","train_accuracy : 95.78933333333333 val_accuracy : 87.264\n","==================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1VgrZpuhrEOE","executionInfo":{"status":"aborted","timestamp":1627552295528,"user_tz":-330,"elapsed":18,"user":{"displayName":"Eshaan Tanwar","photoUrl":"","userId":"13329771561661737362"}}},"source":["fig = plt.figure(figsize = (20, 6))\n","plt.subplot(1, 2, 1)\n","plt.plot(epoch_tr_acc, label='Train Acc')\n","plt.plot(epoch_vl_acc, label='Validation Acc')\n","plt.title(\"Accuracy\")\n","plt.legend()\n","plt.grid()\n","    \n","plt.subplot(1, 2, 2)\n","plt.plot(epoch_tr_loss, label='Train loss')\n","plt.plot(epoch_vl_loss, label='Validation loss')\n","plt.title(\"Loss\")\n","plt.legend()\n","plt.grid()\n","\n","plt.show()"],"execution_count":null,"outputs":[]}]}